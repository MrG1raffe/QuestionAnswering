{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Question Answering - Annexes\n",
    "\n",
    "## Installation de pyserini\n",
    "\n",
    "L’installation est assez délicate, les instruction suivantes sont\n",
    "inspirées de\n",
    "<https://github.com/castorini/pyserini/blob/master/docs/installation.md>:\n",
    "\n",
    "``` shell\n",
    "conda create -n pyserini python=3.10 -y\n",
    "conda activate pyserini\n",
    "conda install -c conda-forge openjdk=11 maven -y\n",
    "conda install -c conda-forge lightgbm nmslib -y\n",
    "conda install -c pytorch faiss-cpu mkl=2021 blas=1.0=mkl pytorch -y\n",
    "pip install pyserini\n",
    "```\n",
    "\n",
    "Une version sans conda devrait marcher aussi, à condition d’avoir Python\n",
    "3.10 et pas une version plus récente:\n",
    "\n",
    "``` shell\n",
    "python -m venv serini\n",
    "source serini/bin/activate\n",
    "sudo apt update\n",
    "sudo apt install default-jdk build-essential\n",
    "pip install faiss-cpu\n",
    "pip install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "pip install pyserini\n",
    "```\n",
    "\n",
    "## Installation des modules Huggingface\n",
    "\n",
    "``` shell\n",
    "pip install datasets\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "Ces deux bibliothèques gèrent le téléchargement des datasets et des\n",
    "modèles pré-entraînés. Le téléchargement se fait une fois pour toute\n",
    "lors de la première exécution.\n",
    "\n",
    "## Installation de Langchain\n",
    "\n",
    "``` shell\n",
    "pip install langchain\n",
    "```\n",
    "\n",
    "## Chargement du dataset `nq_open`"
   ],
   "id": "b8f7a99e-257f-4774-ab06-364891b85884"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nq_open\", split=\"validation\")\n",
    "for batch in dataset.iter(batch_size=1):\n",
    "    print(batch[\"question\"], batch[\"answer\"])"
   ],
   "id": "fb65fdec-8b39-43da-936f-029048951d61"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle probabiliste avec Pyserini"
   ],
   "id": "119cb3c0-34f1-4212-aa8b-c33f3cbd5aef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "\n",
    "searcher = LuceneSearcher.from_prebuilt_index('wikipedia-dpr-100w')\n",
    "hits = searcher.search('How old is Harrisson Ford ?')\n",
    "\n",
    "for i in range(0, 10):\n",
    "    docid = hits[i].docid\n",
    "    score = hits[i].score\n",
    "    content = json.loads(searcher.doc(docid).raw())[\"contents\"]\n",
    "\n",
    "    print(score, docid, content)"
   ],
   "id": "8986fdf4-76f4-4352-99fc-448f8712aed7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet index a été calculé à partir d’une extraction complète de wikipedia.\n",
    "Chaque article a été découpé en passages d’une longueur de 100 mots. Un\n",
    "document de l’index est l’un de ces passages.\n",
    "\n",
    "## Modèle dense avec Pyserini\n",
    "\n",
    "Ne pas l’utiliser tel quel, c’est trop coûteux pour une machine\n",
    "personnelle, ce fragment est juste donné à titre de référence. On voit\n",
    "ici l’encodeur de question\n",
    "`facebook/dpr-question_encoder-single-nq-base` et l’index précalculé\n",
    "avec l’encodeur de documents"
   ],
   "id": "a4ef3f7e-8dfc-4a9b-af90-0c368dc21878"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyserini.search.faiss import FaissSearcher, DprQueryEncoder\n",
    "# \n",
    "# encoder = DprQueryEncoder('facebook/dpr-question_encoder-single-nq-base')\n",
    "# searcher = FaissSearcher.from_prebuilt_index(\n",
    "#     'wikipedia-dpr-100w.dpr-single-nq',\n",
    "#     encoder\n",
    "# )\n",
    "# hits = searcher.search('what is a lobster roll')"
   ],
   "id": "abf4f2d2-78b9-479a-963e-6efd8bd14a0f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s’agit des mêmes documents que précédemment.\n",
    "\n",
    "## Modèle dense avec Fakesearch\n",
    "\n",
    "Il faut télécharger le fichier `fakesearch.py` et le fichier\n",
    "`faiss-validation.pickle`. Les résultats de recherche ont été\n",
    "précalculés et stockés dans un fichier."
   ],
   "id": "d60da462-0246-4851-b879-7850d6aaec4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fakesearch\n",
    "\n",
    "dense_index = fakesearch.load(\"faiss-lucene.pickle)\n",
    "dense_index[\"what is a lobster roll\"]"
   ],
   "id": "aa0a0733-a30c-4796-bc75-51deb06d4e97"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, on ne peut utiliser que les questions du sous-ensemble de\n",
    "validation. On obtiendra une erreur dans le cas contraire:"
   ],
   "id": "8cd7d534-02d4-4fd7-a22d-045447e7ffb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_index[\"How old is Harrison Ford\"]"
   ],
   "id": "f9405b1f-efc7-4d2b-8429-f88847c613b1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle probabiliste avec Fakesearch\n",
    "\n",
    "La recherche pré-calculée n’est à utiliser que si vous n’arrivez\n",
    "vraiment pas à installer `pyserini`.\n",
    "\n",
    "Il faut télécharger le fichier `fakesearch.py` et le fichier\n",
    "`lucence-validation.pickle`. Les résultats de recherche ont été\n",
    "précalculés et stockés dans un fichier."
   ],
   "id": "ecd27206-73d2-4499-83d0-b77ef3c41107"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fakesearch\n",
    "\n",
    "sparse_index = fakesearch.load(\"lucene-validation.pickle)\n",
    "sparse_index[\"what is a lobster roll\"]"
   ],
   "id": "4d5cc5c5-7a00-499d-ace4-babb3036e701"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, on ne peut utiliser que les questions du sous-ensemble de\n",
    "validation. On obtiendra une erreur dans le cas contraire:"
   ],
   "id": "e0f56580-d193-4091-b218-9d185d3c7817"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_index[\"How old is Harrison Ford\"]"
   ],
   "id": "03b9f078-e95b-4c45-aadf-cd2def1bcfcf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT avec le module OpenAI\n",
    "\n",
    "Cet interface est relativement simple, mais limitée à ChatGPT et ne\n",
    "fournit aucun outil pour faciliter l’utilisation des réponses."
   ],
   "id": "48b716ee-9f99-4139-a249-bb3ab1b98284"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=LA_CLÉ_ICI)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who is Joe Biden ?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ],
   "id": "12e8a281-e10f-4e71-8d39-4ca8f89b8643"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT avec Langchain\n",
    "\n",
    "Langchain est un peu plus complexe à utiliser, mais permet d’utiliser\n",
    "beaucoup plus d’outils pratiques et de s’abstraire du modèle de langue\n",
    "utilisé."
   ],
   "id": "c7fe937b-8ec2-4c6c-86f2-ab49dcc75418"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=LA_CLÉ_ICI)\n",
    "llm.invoke(\"what is a lobster roll\")"
   ],
   "id": "805a61cf-6d34-444f-bd58-253958a4ee65"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duckduckgo avec Langchain\n",
    "\n",
    "Voir <https://python.langchain.com/docs/integrations/tools/ddg>"
   ],
   "id": "5a119169-9042-43ea-b7f1-70ab31b8fa68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  duckduckgo-search\n",
    "\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "search.run(\"what is a lobster roll\")"
   ],
   "id": "ea45f618-c3ab-4c1a-af9a-fce67bd594ab"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama2\n",
    "\n",
    "Pour Llama2, on a besoin de:\n",
    "\n",
    "-   Ollama <https://ollama.ai/> pour télécharger et faire tourner le\n",
    "    modèle\n",
    "-   Langchain pour l’utiliser\n",
    "\n",
    "Voir <https://python.langchain.com/docs/integrations/chat/ollama>\n",
    "\n",
    "## GPT2\n",
    "\n",
    "Voir <https://huggingface.co/gpt2>"
   ],
   "id": "68e84f78-6f82-421c-b704-26bf1aba6b16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "pipe(\"what is a lobster roll\")"
   ],
   "id": "b9b5fa1e-01fb-4eca-a3aa-517a32ee106d"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
